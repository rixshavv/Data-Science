{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "#Stemming-reducing a word to its root or stem word .Example eat->eats, eaten,eating\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:07:20.269505Z",
     "start_time": "2025-06-04T10:07:20.257875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writes\",\"written\",\"programming\",\"programs\",\"history\"]\n",
    "for word in words:\n",
    "    print(word+\"-->\"+stemmer.stem(word))"
   ],
   "id": "8e884ad0f31d51e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eaten\n",
      "writes-->write\n",
      "written-->written\n",
      "programming-->program\n",
      "programs-->program\n",
      "history-->histori\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:01:34.923053Z",
     "start_time": "2025-06-04T10:01:34.912863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stemmer.stem(\"congratulations\")\n",
    "#major disadvantage that for some words it give meaningless output or root words"
   ],
   "id": "8ef4b9a512244e3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:06:40.029504Z",
     "start_time": "2025-06-04T10:06:40.014647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_stemmer = RegexpStemmer(\"ing$|s$|e$|able$\",min=4)\n",
    "#It will remove all the words matching with the parameters characters\n",
    "reg_stemmer.stem(\"notiable\")"
   ],
   "id": "dce962cd2f0bfc11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noti'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:08:06.619792Z",
     "start_time": "2025-06-04T10:08:06.611066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "#snowball stemmer is better than porter stemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "for word in words:\n",
    "    print(word+\"-->\"+snowball_stemmer.stem(word))"
   ],
   "id": "d0ab71ce3b455d3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eaten\n",
      "writes-->write\n",
      "written-->written\n",
      "programming-->program\n",
      "programs-->program\n",
      "history-->histori\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#So all these errors and problems in words can be solved through lemmatization which has dictionary of all the words.\n",
    "#it is used in basic projects, and search engines as it is faster than lemmatization"
   ],
   "id": "206a5e3651d1b594"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
